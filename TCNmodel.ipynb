{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TCNmodel.ipynb","provenance":[{"file_id":"1Xr4WP-DRzunHR2NJfhq6s3K9Gz0COcXS","timestamp":1575085567063},{"file_id":"1sWH-Kq4i6VdwKSScpYJObZfFvI2oleDs","timestamp":1574634178628},{"file_id":"1IoGxSYMguwHzAwemCtTj2T5ylzYqHrju","timestamp":1574566995621}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5WialQ1W1ERL","colab_type":"code","outputId":"eb30ddb8-c62b-4ef3-8bbe-dd61d5ab4b3e","executionInfo":{"status":"ok","timestamp":1575133201539,"user_tz":300,"elapsed":19892,"user":{"displayName":"Pooja Consul","photoUrl":"","userId":"08813747384597539541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kbbRzsqb1Q5_","colab_type":"code","outputId":"eada307a-4b63-4fde-96d1-8e359eabe901","executionInfo":{"status":"ok","timestamp":1575152196497,"user_tz":300,"elapsed":19605,"user":{"displayName":"Pooja Consul","photoUrl":"","userId":"08813747384597539541"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NSCboqhv1UpT","colab_type":"code","outputId":"d9c2c84c-78c4-44ef-cc84-81bed4892879","executionInfo":{"status":"ok","timestamp":1575152196500,"user_tz":300,"elapsed":1175,"user":{"displayName":"Pooja Consul","photoUrl":"","userId":"08813747384597539541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/'My Drive'/'CIS 520 Project'"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CIS 520 Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zMPY46Gb1VZO","colab_type":"code","colab":{}},"source":["#imports\n","import warnings\n","import pandas as pd\n","import numpy as np\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot\n","from collections import Counter\n","import seaborn as sns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ve2wzw6_1Z3F","colab_type":"code","colab":{}},"source":["def get_data(csvfile):\n","  df = pd.read_pickle(csvfile)\n","  x, y = df['text'].tolist(), df['stars_x'].tolist()\n","  return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNIOMyty6JJi","colab_type":"code","outputId":"a80ef21a-e73a-44f6-e415-ae3ca765235d","executionInfo":{"status":"ok","timestamp":1575152199615,"user_tz":300,"elapsed":3380,"user":{"displayName":"Pooja Consul","photoUrl":"","userId":"08813747384597539541"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["#imports \n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Input\n","from keras.layers import LSTM, Conv1D, GlobalMaxPooling1D,MaxPooling1D, TimeDistributed\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.utils import to_categorical\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.naive_bayes import MultinomialNB \n","import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"9rkIb5pbQSrg","colab_type":"code","colab":{}},"source":["#TCN intialization cell\n","# https://github.com/titu1994/keras-neural-alu/blob/master/nac.py\n","from keras.engine import Layer\n","from keras.engine import InputSpec\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","from keras import backend as K\n","\n","from keras.utils.generic_utils import get_custom_objects\n","\n","\n","class NAC(Layer):\n","    def __init__(self, units,\n","                 kernel_W_initializer='glorot_uniform',\n","                 kernel_M_initializer='glorot_uniform',\n","                 kernel_W_regularizer=None,\n","                 kernel_M_regularizer=None,\n","                 kernel_W_constraint=None,\n","                 kernel_M_constraint=None,\n","                 **kwargs):\n","        \"\"\"\n","        Neural Accumulator.\n","        # Arguments:\n","            units: Output dimension.\n","            kernel_W_initializer: Initializer for `W` weights.\n","            kernel_M_initializer: Initializer for `M` weights.\n","            kernel_W_regularizer: Regularizer for `W` weights.\n","            kernel_M_regularizer: Regularizer for `M` weights.\n","            kernel_W_constraint: Constraints on `W` weights.\n","            kernel_M_constraint: Constraints on `M` weights.\n","            epsilon: Small factor to prevent log 0.\n","        # Reference:\n","        - [Neural Arithmetic Logic Units](https://arxiv.org/abs/1808.00508)\n","        \"\"\"\n","        super(NAC, self).__init__()\n","        self.units = units\n","\n","        self.kernel_W_initializer = initializers.get(kernel_W_initializer)\n","        self.kernel_M_initializer = initializers.get(kernel_M_initializer)\n","        self.kernel_W_regularizer = regularizers.get(kernel_W_regularizer)\n","        self.kernel_M_regularizer = regularizers.get(kernel_M_regularizer)\n","        self.kernel_W_constraint = constraints.get(kernel_W_constraint)\n","        self.kernel_M_constraint = constraints.get(kernel_M_constraint)\n","\n","        self.supports_masking = True\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) >= 2\n","        input_dim = input_shape[-1]\n","\n","        self.W_hat = self.add_weight(shape=(input_dim, self.units),\n","                                     name='W_hat',\n","                                     initializer=self.kernel_W_initializer,\n","                                     regularizer=self.kernel_W_regularizer,\n","                                     constraint=self.kernel_W_constraint)\n","\n","        self.M_hat = self.add_weight(shape=(input_dim, self.units),\n","                                     name='M_hat',\n","                                     initializer=self.kernel_M_initializer,\n","                                     regularizer=self.kernel_M_regularizer,\n","                                     constraint=self.kernel_M_constraint)\n","\n","        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n","        self.built = True\n","\n","    def call(self, inputs, **kwargs):\n","        W = K.tanh(self.W_hat) * K.sigmoid(self.M_hat)\n","        a = K.dot(inputs, W)\n","        return a\n","\n","    def compute_output_shape(self, input_shape):\n","        assert input_shape and len(input_shape) >= 2\n","        assert input_shape[-1]\n","        output_shape = list(input_shape)\n","        output_shape[-1] = self.units\n","        return tuple(output_shape)\n","\n","    def get_config(self):\n","        config = {\n","            'units': self.units,\n","            'kernel_W_initializer': initializers.serialize(self.kernel_W_initializer),\n","            'kernel_M_initializer': initializers.serialize(self.kernel_M_initializer),\n","            'kernel_W_regularizer': regularizers.serialize(self.kernel_W_regularizer),\n","            'kernel_M_regularizer': regularizers.serialize(self.kernel_M_regularizer),\n","            'kernel_W_constraint': constraints.serialize(self.kernel_W_constraint),\n","            'kernel_M_constraint': constraints.serialize(self.kernel_M_constraint),\n","        }\n","\n","        base_config = super(NAC, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","\n","get_custom_objects().update({'NAC': NAC})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDe-HzhyEurZ","colab_type":"code","colab":{}},"source":["#preparing X and y!!!\n","csvfile = 'reviews_bow.csv'\n","reviews, stars = get_data(csvfile)\n","warnings.filterwarnings(\"ignore\")\n","tempy, tempx = stars[:1000000], reviews[:1000000]\n","print('Data loaded')\n","\n","#preparing y\n","y = np.array(tempy, dtype=np.uint8)\n","ymulti = y-1\n","y = to_categorical(ymulti, num_classes=5)\n","print('y prepared', y.shape)\n","\n","#preparing x\n","vocab_size = 50000 #will use most frequent 50k words\n","num_words = 200 #97%coverage for reviews\n","tokenizer = Tokenizer(num_words = vocab_size)\n","tokenizer.fit_on_texts(tempx)\n","sequences = tokenizer.texts_to_sequences(tempx)\n","padded_str = pad_sequences(sequences, maxlen = num_words)\n","#type changed here to use less memory \n","x = np.array(padded_str, dtype=np.uint16)\n","# x = np.expand_dims(x, axis = 2)\n","print('x prepared', x.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWc26gUVerNm","colab_type":"code","colab":{}},"source":["#class weights\n","# https://stackoverflow.com/questions/43481490/keras-class-weights-class-weight-for-one-hot-encoding\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","y_integers = np.argmax(y, axis=1)\n","class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n","d_class_weights = dict(enumerate(class_weights))\n","print(d_class_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mECVtWioQzfD","colab_type":"code","colab":{}},"source":["def TCN_model():\n","  # create model\n","  # global d_class_weights\n","  i = Input(batch_shape=(None, 1, 200))\n","  # i = Input(batch_shape=(None, 44, 1024))\n","  o = NAC(2048, kernel_size=11, nb_stacks=2, dilations=[1, 2, 4, 8, 16], use_gating = True)(i)\n","  o = LSTM(200, return_sequences=False, dropout=0.25)(o)\n","  o = Dense(5, activation='sigmoid')(o)    \n","  model = Model(inputs=[i], outputs=[o])\n","  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','accuracy'])\n","  print(model.summary())\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NG5AtJrkH4fT","colab_type":"code","colab":{}},"source":["#CNN\n","#train-test\n","tempx = np.expand_dims(x, axis = 1)\n","tempy = to_categorical(ymulti, num_classes=5)\n","X_train, X_test, y_train, y_test = train_test_split(tempx, tempy, test_size=0.2, random_state=42, stratify = y)\n","print('X train shape: ', type(X_train), ' y train shape: ', type(y_train))\n","print('X train type: ', X_train.shape, ' y train type: ', y_train.shape)\n","\n","model = TCN_model()\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose = 1, class_weight=d_class_weights)\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","model.save('tcn.h5')\n","pred = model.predict_classes(X_test)\n","y_int = [np.argmax(r) for r in y_test]\n","print(scores)\n","print(metrics.accuracy_score(y_int, pred))\n","print(metrics.classification_report(y_int, pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SD1WC89wTeHD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}