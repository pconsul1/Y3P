{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataclean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy5qvKK2j-8D",
        "colab_type": "code",
        "outputId": "ffe8feec-c07b-4dab-ecdf-b926f10c60ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7a0fOmCkEEb",
        "colab_type": "code",
        "outputId": "0d51990c-e301-482c-d305-caa6ba2702ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIF-hh3BkFvL",
        "colab_type": "code",
        "outputId": "399f044e-d076-484d-c654-74b450c4091e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/'My Drive'/'CIS 520 Project'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CIS 520 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCwuVlFV2tC6",
        "colab_type": "text"
      },
      "source": [
        "This notebook cleans the reviews from restaurant_reviews.csv file and saves the reviews as bag of words along with the corresponding rating. The star and review column name remain the same i.e. \"stars_x\" and \"text\". \n",
        "\n",
        "1. \"stars_x\" column is of type int and only contains values from 1-5.\n",
        "2. \"text\" column contains a list of words in the review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuQQ4nViMAK2",
        "colab_type": "code",
        "outputId": "4c041e64-5734-4339-85f8-f06c6d3232ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#imports\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# from vocabulary import Vocabulary\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import configparser"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NKqyFK-LNSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading 'stars_x' and 'text' columns\n",
        "pd.options.display.max_colwidth = 10000\n",
        "df = pd.read_csv('restaurant_reviews.csv', usecols = ['stars_x', 'text'], engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-XDxq1MMfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking unique stars_x values\n",
        "print(df['stars_x'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nWkEjB7PlKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_text = df[['text']]\n",
        "df_text.isnull()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1eWmw4MbnOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df['stars_x'].isnull() == True]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Uc7JLh4Q37",
        "colab_type": "text"
      },
      "source": [
        "Setting data types of \"stars_x\" column as int and \"text\" column as string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnCEsjmic37i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing null value, setting type for columns\n",
        "df = df.dropna()\n",
        "df = df.astype({'text':str, 'stars_x':'int32'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAGbKBaRdJiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw9j_YlT3gC-",
        "colab_type": "text"
      },
      "source": [
        "Following tasks are performed on the reviews - \n",
        "1. spaces stripped\n",
        "2. \\n, \\r removed\n",
        "3. word tokenization\n",
        "4. conversion of words to lower case\n",
        "5. removal of stopwords\n",
        "6. removal of punctuations\n",
        "7. lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLPC-HEi51H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = 0\n",
        "def clean_text(col):\n",
        "  #run check\n",
        "  global it\n",
        "  if (it%100000==0):\n",
        "    print(it)\n",
        "  it+=1\n",
        "  \n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  stopWords = set(stopwords.words('english'))\n",
        "  #stirp spaces\n",
        "  col = col.strip()\n",
        "  #remove /n, /r\n",
        "  col = col.replace('\\r', ' ')\n",
        "  col = col.replace('\\n', ' ')\n",
        "  words = word_tokenize(col)\n",
        "  bow = []  \n",
        "  for word in words:\n",
        "      word = word.lower()\n",
        "      if word not in stopWords and word not in string.punctuation:\n",
        "          new_word = lemmatizer.lemmatize(word)\n",
        "          bow.append(new_word)\n",
        "  return bow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLmqDlIdQBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bow_text(df):\n",
        "  df['text'] = df['text'].apply(clean_text)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KZpLUeo37ly",
        "colab_type": "text"
      },
      "source": [
        "Bag of word reviews are stored in reviews_bow.csv. To read this file using pandas use pandas.read_pickle()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg04SR62j4Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfnew = bow_text(df)\n",
        "dfnew.to_pickle('reviews_bow.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}